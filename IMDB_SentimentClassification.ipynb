{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8401baf7",
   "metadata": {},
   "source": [
    "# Sentiment Classification on IMDB Dataset\n",
    "\n",
    "IMDB dataset having 50K movie reviews for natural language processing or Text analytics.\n",
    "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training and 25,000 for testing. So, predict the number of positive and negative reviews using either classification or deep learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3818e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23bc9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d236926",
   "metadata": {},
   "source": [
    "# Basic Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a6a274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows :  50000\n",
      "Number of columns :  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows : \",data.shape[0])\n",
    "print(\"Number of columns : \", data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f72f70b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdf4a67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentiment_count\n",
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15396c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "973579a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = data[\"review\"][1]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea6fffb",
   "metadata": {},
   "source": [
    "## Inferences from Analysis\n",
    "**`Note`** \n",
    "- We have a balanced Dataset, with just 2 categories : Positive and Negative.\n",
    "- No missing values\n",
    "- The dataset contains redundant words and html syntaxes.\n",
    "- Punctuations/stopwords are present in equal distribution in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bab537b",
   "metadata": {},
   "source": [
    "# [Text preparation](https://eugenia-anello.medium.com/nlp-tutorial-series-d0baaf7616e0)\n",
    "\n",
    "## Data Cleaning and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387bb04a",
   "metadata": {},
   "source": [
    "#### [1. Need To remove HTML tags from strings](https://stackoverflow.com/questions/9662346/python-code-to-remove-html-tags-from-a-string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b82d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ae72437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleantext = BeautifulSoup(text, \"lxml\").text\n",
    "cleantext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac235d6",
   "metadata": {},
   "source": [
    "#### 2. [Remove punctuation, special-character from string](https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string)\n",
    "- we will remove everything except lower/upper case letters using Regular Expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe03d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production  The filming technique is very unassuming  very old time BBC fashion and gives a comforting  and sometimes discomforting  sense of realism to the entire piece  The actors are extremely well chosen  Michael Sheen not only  has got all the polari  but he has all the voices down pat too  You can truly see the seamless editing guided by the references to Williams  diary entries  not only is it well worth the watching but it is a terrificly written and performed piece  A masterful production about one of the great master s of comedy and his life  The realism really comes home with the little things  the fantasy of the guard which  rather than use the traditional  dream  techniques remains solid then disappears  It plays on our knowledge and our senses  particularly with the scenes concerning Orton and Halliwell and the sets  particularly of their flat with Halliwell s murals decorating every surface  are terribly well done '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleantext = re.sub('\\[[^]]*\\]', ' ', cleantext) #remove '\\'\n",
    "cleantext = re.sub('[^a-zA-Z]', ' ', cleantext) #remove any character except a-z or A-Z\n",
    "cleantext = re.sub(r'[^\\w\\s]',' ', cleantext)   #remove punctuation\n",
    "cleantext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94873b7b",
   "metadata": {},
   "source": [
    "#### [3. Remove stopwords from data](https://www.geeksforgeeks.org/removing-stop-words-nltk-python/)\n",
    "\n",
    "stopwords : Words that are not very useful for Machine learning hence need to ignore/remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fa06578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('stopwords')                                     #download if require\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8eb8e3",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "- First converting all reviews into lower_case\n",
    "- Stopwords removal - since stopwords removal works on every word in your text we need to split the text.\n",
    "- Split the text into tokens, the string is converted into a list, where each element corresponds to a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b58d24ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleantext= cleantext.lower()                # converting text to lower letters\n",
    "stopword = set(stopwords.words('english'))  # use set so that takes unique value only\n",
    "tokens= cleantext.split()\n",
    "token_list = []\n",
    "for token in tokens:\n",
    "    if token not in stopword:               #if splitted text not in stopwords than update the list\n",
    "        token_list.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3864f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e845a9",
   "metadata": {},
   "source": [
    "## Normalize Words:-\n",
    "- Converting words to its base form.\n",
    "- **For example**, playing, plays and play can seem different to the computer, but they are the same thing.\n",
    "\n",
    "### [4. Lemmatization vs Stemming](https://www.tutorialspoint.com/natural_language_toolkit/natural_language_toolkit_stemming_lemmatization.htm#)\n",
    "\n",
    "- Stemming : convert word into its stem word, but cann't retain its meaning or context\n",
    "- Lemmatization : It converts the word into its root word and also retain the meaning/context of the words, means it will also provide us a valid form of word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e082fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47ba1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d45f466",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78ef7f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wonderful little production filming technique unassuming old time bbc fashion give comforting sometimes discomforting sense realism entire piece actor extremely well chosen michael sheen got polari voice pat truly see seamless editing guided reference williams diary entry well worth watching terrificly written performed piece masterful production one great master comedy life realism really come home little thing fantasy guard rather use traditional dream technique remains solid disappears play knowledge sens particularly scene concerning orton halliwell set particularly flat halliwell mural decorating every surface terribly well done'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_word = []\n",
    "for token in token_list:\n",
    "    lemma_word.append(lemmatizer.lemmatize(token))\n",
    "\n",
    "join_text = ' '.join(lemma_word)\n",
    "join_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3c5579",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4778c4f9",
   "metadata": {},
   "source": [
    "## Vector / mathematical Representation of words\n",
    "- Cleaned text isn’t enough to be passed directly to the classification model. The features need to be numeric, not strings\n",
    "\n",
    "#### To vectorize the text we have following Methods\n",
    "\n",
    "1. CountVectorizer (Bag of Words Model)\n",
    "2. TfidfVectorizer (Bag of Words Model)\n",
    "3. Keras Tokenizer (Embedding)\n",
    "4. Word embedding : \n",
    "> a. word2vec  \n",
    "> b. glove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1be7733",
   "metadata": {},
   "source": [
    "## Bag of words  (CountVectorizer )\n",
    "- It’s an algorithm that transforms the text into fixed-length vectors. This is possible by counting the number of times the word is present in a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2cbebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer            \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2878c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "corpus.append(join_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6ddbd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1,\n",
       "        1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer()\n",
    "BOW = vec.fit_transform(corpus)\n",
    "BOW.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff9c391",
   "metadata": {},
   "source": [
    "- So we can see the data has become numeric with 1,2 and 3s based on the number of times they appear in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4238c5c4",
   "metadata": {},
   "source": [
    "# TFIDF\n",
    "\n",
    "- TF stands for Text Frequency which means how many times a word (term) appears in a text (document).\n",
    "- IDF means Inverse Document Frequency and is calculated as log(# of documents in corpus/# of documents containing the term).\n",
    "\n",
    "- Finally **TF-IDF score is calculated as TF * IDF**\n",
    "\n",
    "**`Note`**\n",
    "- IDF acts as a balancing factor and diminishes the weight of terms that occur very frequently in the document set and increases the weight of terms that occur rarely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a5aa7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.19425717, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.19425717, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.19425717,\n",
       "        0.09712859, 0.09712859, 0.19425717, 0.09712859, 0.09712859,\n",
       "        0.19425717, 0.09712859, 0.19425717, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.19425717, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.29138576, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf = vectorizer.fit_transform(corpus)\n",
    "tf_idf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2855a231",
   "metadata": {},
   "source": [
    "### Function for doing all the datacleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71b3cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check progress of loop working in python\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66aa84d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaner(data):\n",
    "    clean_data = []\n",
    "    for sentence in tqdm(data):\n",
    "        cleantext = BeautifulSoup(sentence, \"lxml\").text #html tags\n",
    "        cleantext = re.sub('\\[[^]]*\\]', ' ', cleantext)\n",
    "        cleantext = re.sub('[^a-zA-Z]', ' ', cleantext)\n",
    "        cleantext = re.sub(r'[^\\w\\s]','',cleantext) #\n",
    "        cleantext = [token for token in cleantext.lower().split() if token not in stopword] #stopword\n",
    "        clean_text = ' '.join([lemmatizer.lemmatize(token) for token in cleantext])\n",
    "        clean_data.append(clean_text.strip())                  #remove extra space\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76d05440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                                        | 805/50000 [00:01<01:13, 666.32it/s]C:\\Users\\hp\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [01:13<00:00, 684.58it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_data = data_cleaner(data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6599ce8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'short film inspired soon full length feature spatula madness hilarious piece contends similar cartoon yielding multiple writer short film star edward spatula fired job join fight evil spoon premise allows funny content near beginning barely present remainder feature film minute running time absorbed odd ball comedy small musical number unfortunately much else lie plot set really time show surely follows plot better many high budget hollywood film film worth watching least time take expect deep story'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1122ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting sentiment to numeric form 1 for postive label and 0 for negative label\n",
    "data['sentiment'].replace({'negative':0,'positive':1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c863a4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef953cb",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9959228a",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "- We will now apply all the techniques that we discussed on the whole dataset but there is no test dataset so we will keep 80% of the data aside to test the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4667bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6baaf58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['review'], data['sentiment'], test_size=0.2, random_state=42 ,stratify=data[\"sentiment\"])# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4afb06e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,) (40000,)\n",
      "(10000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d1c9d3",
   "metadata": {},
   "source": [
    "## Cleaning only the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a70351d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                        | 673/40000 [00:00<00:53, 737.69it/s]C:\\Users\\hp\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 40000/40000 [00:59<00:00, 677.34it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_traindata = data_cleaner(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee08e1",
   "metadata": {},
   "source": [
    "### Validating with an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bedb7dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Martha Plimpton has done some prestigious movies, working with River Phoenix and Harrison Ford, but she was never able to expand her limited, tomboyish appeal into the same class as, say, Molly Ringwald. This film, which was barely released, is just an extension of her late '80s/early '90s attempts to find a screen-persona which was identifiable to moviegoers, and it represents another failure. Plimpton plays a troubled young woman who finds out on her 21st birthday that she was adopted and--worse than that--was actually abandoned as an infant on her parents' doorstep! She sets out to find her biological mother and father, but the viewer has no clue why she'd even want to (would simple curiosity give her this much determination?). Unattractive material given sitcom handling; it starts off on the wrong foot and never recovers. Plimpton gives a sour, surly performance, but Hector Elizondo and Mary Kay Place are fine as her adoptive parents. *1/2 from ****\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a23c25eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'martha plimpton done prestigious movie working river phoenix harrison ford never able expand limited tomboyish appeal class say molly ringwald film barely released extension late early attempt find screen persona identifiable moviegoer represents another failure plimpton play troubled young woman find st birthday adopted worse actually abandoned infant parent doorstep set find biological mother father viewer clue even want would simple curiosity give much determination unattractive material given sitcom handling start wrong foot never recovers plimpton give sour surly performance hector elizondo mary kay place fine adoptive parent'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_traindata[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20009a64",
   "metadata": {},
   "source": [
    "## Cleaning test dataset separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74234c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:14<00:00, 674.86it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_testdata = data_cleaner(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c41d526",
   "metadata": {},
   "source": [
    "### Validating with an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2cf6a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is not a GREAT movie as tho the cast (especially the kids) admirably help to carry along this very sad yet contrived plot it is filled with cliché upon cliché. Poor family in 50's mid America, dying mother, alcoholic father, 10 children (1 of whom has epilepsy) and an awful decision to be made. Its very easy to watch and some of the kids performances are moving without being sickly or naff. And little Frank and Warrnen steal the show for me with the last scene leaving me bawling no matter how many times I see it. A great rainy afternoon movie i recommend to all. Only those with the hardest of hearts could fail to be moved by it. Not on a par to Sophies Choice but a good TV movie equivalent!!!\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b187913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great movie tho cast especially kid admirably help carry along sad yet contrived plot filled clich upon clich poor family mid america dying mother alcoholic father child epilepsy awful decision made easy watch kid performance moving without sickly naff little frank warrnen steal show last scene leaving bawling matter many time see great rainy afternoon movie recommend hardest heart could fail moved par sophies choice good tv movie equivalent'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_testdata[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "377e2b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f62559",
   "metadata": {},
   "source": [
    "## Model 1 : Logistic Regression\n",
    "**Important tuning parameters for Logistic Regression:**\n",
    "\n",
    "- C       : inverse of regularization strength (lambda)\n",
    "- penalty : type of regularization - 'L1', 'L2', 'elasticnet'\n",
    "- solver  : algorithm used for optimization - 'liblinear','lbfgs', 'newton-cg', 'sag', 'saga' \n",
    "\n",
    "> [Advance optimization solver **`lbfgs`**](https://www.youtube.com/watch?v=j4TJZBIDR28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd9df722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a128028",
   "metadata": {},
   "source": [
    "#### Vectorization : TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e82fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_LRvec = TfidfVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "tfidf_LRvec_train = tfidf_LRvec.fit_transform(clean_traindata)\n",
    "tfidf_LRvec_test = tfidf_LRvec.transform(clean_testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5469c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model = LogisticRegression(solver='lbfgs')\n",
    "LR_model.fit(tfidf_LRvec_train, y_train)\n",
    "predict_LR = LR_model.predict(tfidf_LRvec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84cd6e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.88      0.89      5000\n",
      "    Positive       0.89      0.91      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Confusion Matrix: \n",
      " [[4416  584]\n",
      " [ 461 4539]]\n",
      "Accuracy: \n",
      " 0.8955\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report: \\n\", classification_report(y_test, predict_LR,target_names=['Negative','Positive']))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, predict_LR))\n",
    "print(\"Accuracy: \\n\", accuracy_score(y_test, predict_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af43b4f4",
   "metadata": {},
   "source": [
    "## Model 2 : LinearSVC\n",
    "\n",
    "- It applies a **Linear Kernal Function** to Perform Classification.\n",
    "- Estimator used is **liblinear**\n",
    "- It Minimizes the **squared hinge loss**\n",
    "- It has Additional Parameter of **penalty normalization: L1, L2**; L2 is default selected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e44e1fe",
   "metadata": {},
   "source": [
    "### Vectorization : TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ec15d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "tfidf_SVCvec_train = tfidf_vec.fit_transform(clean_traindata)\n",
    "tfidf_SVCvec_test = tfidf_vec.transform(clean_testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ac71de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_svc = LinearSVC(C=0.5, random_state=42)   #C=Regularization Parameter\n",
    "linear_svc.fit(tfidf_SVCvec_train, y_train)\n",
    "\n",
    "predict_SVC = linear_svc.predict(tfidf_SVCvec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03ac91b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.89      0.90      5000\n",
      "    Positive       0.89      0.92      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Confusion Matrix: \n",
      " [[4447  553]\n",
      " [ 414 4586]]\n",
      "Accuracy: \n",
      " 0.9033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, predict_SVC,target_names=['Negative','Positive']))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, predict_SVC))\n",
    "print(\"Accuracy: \\n\", accuracy_score(y_test, predict_SVC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f4801",
   "metadata": {},
   "source": [
    "## Model 3 : Multinomial Naive Bayes Classifier\n",
    "\n",
    "- Bayesian model uses prior probabilities to predict posterior probabilites which is **helpful for classification with discrete features like text classification.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1540be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec_NB = TfidfVectorizer(ngram_range=(1, 1))\n",
    "tfidf_vec_train_NB = tfidf_vec_NB.fit_transform(clean_traindata)\n",
    "tfidf_vec_test_NB = tfidf_vec_NB.transform(clean_testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b79fad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "multi_clf = MultinomialNB()\n",
    "multi_clf.fit(tfidf_vec_train_NB, y_train)\n",
    "\n",
    "predict_NB = multi_clf.predict(tfidf_vec_test_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4dabb49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.86      0.88      0.87      5000\n",
      "    Positive       0.88      0.86      0.87      5000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "Confusion Matrix: \n",
      " [[4403  597]\n",
      " [ 719 4281]]\n",
      "Accuracy: \n",
      " 0.8684\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report: \\n\", classification_report(y_test, predict_NB,target_names=['Negative','Positive']))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, predict_NB))\n",
    "print(\"Accuracy: \\n\", accuracy_score(y_test, predict_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5457828f",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- **LinearSVC** using **TF-IDF vectorization** gives the maximum accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd23b86",
   "metadata": {},
   "source": [
    "## Testing\n",
    "[Test on user data review link](https://www.imdb.com/title/tt6443346/reviews?ref_=tt_urv)\n",
    "\n",
    "- 0: Negative; 1: positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e93a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_0 = [\"I hoped 'Black Adam' would be a decent entry in DC's recent output as its linked with 'Shazam' which might be their best recent movie. But nope. Its another CGI filled dud On the plus side there is an effort put into the story and Dwayne Johnson and his rediculusly strong shoulders buldging from his costume are 100 percent real amongst all the boring CGI. But all the team building with rubbish characters no one cares about has already been DC's downfall with the justice league, Suicide squad and even that Harley Quinn movie. And it's takes up too much time here too. There's not enough time dedicated to making us care about any of these minor characters and their random powers. Just action, action, action that doesn't matter when you don't care about anyone in the movie. There's some decent gags in the movie I suppose. But overall its just alot of green screen and feels like your watching a computer game instead of a movie. It's more 'Aquaman' than 'Shazam.' So if you liked that one you'll probably like this\"]\n",
    "text_1 = [\"Black Adam is not without its flaws, but i still enjoy the hell out of it, the problem that i have with Black Adam is that i never really buy all the Kahndaq people 100%, in the end i only still buy half of it, but i still fine with it, it's not like their characters are terrible, it just most of the time they are doing just a poor performance except the actress who played the mom and probably Ishmael for the most part, at least i still got some of the laughs from one of them, some of the slower scene was sometimes misplaced including some of the flashback, and some nit picky here and there, the rest of Black Adam is an exciting comic book film that fills with a very impressive battle that also fills with dazzling visual and cool style, Black Adam himself played incredibly well by Dwayne Johnson, he was just unstoppable in the most badass way, Justice Society has just become one of my favorite superhero team specifically in movies, they are fun and they are great, Hawkman, Doctor Fate, Cyclone, and Atom Smasher all of them are a hit for me, i love every single one of them, though i do wish they have something more with Doctor Fate because i think Pierce Brosnan was just unbelievably good playing the characters, again at least we do still have that one moment, i would love to see Justice Society again in movie maybe even their own movie, i would also love to have a specifically Doctor Fate standalone or a prequel film, and last but not least, the main villain, i think the main villain is doing as fine as most of the hero in the movie, so overall Black Adam is a quite a fun ride, 2 hours did feel quite goes by, an exciting back and forth battle that fills with dazzling visual effect and style, great score, great sound, great performances for most of the cast, being the first original DCEU movie that release in theaters only since WW84, Black Adam is not perfect but it's still great, it's still fun, it's still fascinating, it's still exciting, and i enjoy the hell out of it.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e97db0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#Testing on multinomial_NB classifier :-\n",
    "text_vec = tfidf_vec_NB.transform(text_0)\n",
    "print(multi_clf.predict(text_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "758e94a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#Testing on linear_SVC classifier :-\n",
    "text_vec = tfidf_vec.transform(text_0)\n",
    "print(linear_svc.predict(text_vec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "63963b3f4c440940f0b94a3100916033a226cb4f45979123153792d60aa56d6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
